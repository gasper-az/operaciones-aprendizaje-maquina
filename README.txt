
# Proyecto Final - MLOps1 (CEIA - FIUBA)

ImplementaciÃ³n de un modelo de Machine Learning (**Body Fat Analysis**) en un entorno productivo simulado con **Docker Compose**.  
El objetivo es desplegar y orquestar un pipeline de MLOps con los siguientes servicios:

- **Apache Airflow**: orquestaciÃ³n de flujos de trabajo (DAGs de entrenamiento y predicciÃ³n).
- **MLflow**: gestiÃ³n del ciclo de vida de modelos (tracking, versionado y registro).
- **FastAPI**: servicio REST para exponer el modelo entrenado.
- **MinIO (S3 compatible)**: almacenamiento de datasets y artefactos de modelos.
- **PostgreSQL**: base de datos backend para MLflow y Airflow.
- **Valkey (Redis fork)**: backend para ejecuciÃ³n distribuida de Airflow.


Entrega 1
================
* Notebook + train.py loggeando en MLflow.
* DAG de entrenamiento bÃ¡sico corriendo.
* API /health y /predict sirviendo un modelo fijo.
* README inicial.



Entrega final
===============
* DAG con hiperparÃ¡metros + promociÃ³n a Registry.
* Batch predict funcionando en Airflow.
* API usando modelo en Production.
* DocumentaciÃ³n + tests bÃ¡sicos.


## ðŸ“‚ Estructura de carpetas


â”œâ”€â”€ notebooks/ # ExploraciÃ³n y prototipado de modelos
â”‚ â””â”€â”€ body_fat_analysis.ipynb
â”‚
â”œâ”€â”€ ml/ # CÃ³digo fuente del modelo
â”‚ â”œâ”€â”€ train.py # Entrenamiento y guardado del modelo
â”‚ â”œâ”€â”€ infer.py # PredicciÃ³n en batch
â”‚ â”œâ”€â”€ data_utils.py # Utilidades de carga y preprocesamiento
â”‚ â””â”€â”€ config.yaml # ConfiguraciÃ³n de hiperparÃ¡metros y paths
â”‚
â”œâ”€â”€ airflow/
â”‚ â”œâ”€â”€ dags/ # DAGs de Airflow
â”‚ â”‚ â”œâ”€â”€ train_model_dag.py
â”‚ â”‚ â””â”€â”€ batch_predict_dag.py
â”‚ â”œâ”€â”€ logs/ # Logs (excluidos del repo)
â”‚ â””â”€â”€ plugins/ # Operadores y hooks personalizados
â”‚
â”œâ”€â”€ api/ # Servicio de inferencia con FastAPI
â”‚ â”œâ”€â”€ app.py
â”‚ â”œâ”€â”€ schemas.py
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ utilities/
â”‚ â””â”€â”€ scripts/ # Scripts auxiliares
â”‚ â”œâ”€â”€ seed_minio.sh # Inicializar buckets y subir dataset
â”‚ â””â”€â”€ promote_model.py # Promover modelo en MLflow Registry
â”‚
â”œâ”€â”€ DOCKERFILES/ # Dockerfiles personalizados (opcional)
â”‚
â”œâ”€â”€ requirements.txt # Dependencias globales del proyecto
â”œâ”€â”€ mlflow.sql # Script de inicializaciÃ³n de la DB de MLflow
â”œâ”€â”€ docker-compose.yaml # OrquestaciÃ³n de servicios
â””â”€â”€ README.md # DocumentaciÃ³n del proyecto


