# Operaciones de Aprendizaje de MÃ¡quina

## Integrantes

- Acevedo Zain, Gaspar (acevedo.zain.gaspar@gmail.com)
- Chunga, Juan Miguel (juanmiguel.ch2014@gmail.com)
- Gonzalez, Juan (juan.gonzalez.working@gmail.com)
- Lauro, Rodrigo (ing.rodrigo.lauro@gmail.com)
- Rodrigues da Cruz, NicolÃ¡s (Nicolasrdc151@gmail.com)

## DescripciÃ³n

ImplementaciÃ³n de un modelo de Machine Learning (**Body Fat Analysis**) en un entorno productivo simulado con **Docker Compose**.  
El objetivo es desplegar y orquestar un pipeline de MLOps con los siguientes servicios:

- **Apache Airflow**: orquestaciÃ³n de flujos de trabajo (DAGs de entrenamiento y predicciÃ³n).
- **MLflow**: gestiÃ³n del ciclo de vida de modelos (tracking, versionado y registro).
- **FastAPI**: servicio REST para exponer el modelo entrenado.
- **MinIO (S3 compatible)**: almacenamiento de datasets y artefactos de modelos.
- **PostgreSQL**: base de datos backend para MLflow y Airflow.
- **Valkey (Redis fork)**: backend para ejecuciÃ³n distribuida de Airflow.

### Entrega 1

- Notebook loggeando en MLflow.
- DAG de entrenamiento bÃ¡sico corriendo.
- README inicial.

### Entrega final

- DAG con hiperparÃ¡metros + promociÃ³n a Registry.
- Batch predict funcionando en Airflow.
- API usando modelo en Production.
- DocumentaciÃ³n + tests bÃ¡sicos.

### ðŸ“‚ Estructura de carpetas

```YAML
â”œâ”€â”€ notebooks/ # ExploraciÃ³n y prototipado de modelos
â”‚ â””â”€â”€ body_fat_analysis.ipynb
â”‚
â”œâ”€â”€ ml/ # CÃ³digo fuente del modelo
â”‚ â”œâ”€â”€ train.py # Entrenamiento y guardado del modelo
â”‚ â”œâ”€â”€ infer.py # PredicciÃ³n en batch
â”‚ â”œâ”€â”€ data_utils.py # Utilidades de carga y preprocesamiento
â”‚ â””â”€â”€ config.yaml # ConfiguraciÃ³n de hiperparÃ¡metros y paths
â”‚
â”œâ”€â”€ airflow/
â”‚ â”œâ”€â”€ dags/ # DAGs de Airflow
â”‚ â”‚ â”œâ”€â”€ train_model_dag.py
â”‚ â”‚ â””â”€â”€ batch_predict_dag.py
â”‚ â”œâ”€â”€ logs/ # Logs (excluidos del repo)
â”‚ â””â”€â”€ plugins/ # Operadores y hooks personalizados
â”‚
â”œâ”€â”€ api/ # Servicio de inferencia con FastAPI
â”‚ â”œâ”€â”€ app.py
â”‚ â”œâ”€â”€ schemas.py
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ utilities/
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ mlflow.sql
â”‚ â”œâ”€â”€ seed_minio.sh # Inicializar buckets y subir dataset
â”‚ â””â”€â”€ promote_model.py # Promover modelo en MLflow Registry
â”‚
â”œâ”€â”€ dockerfiles/
â”‚   â””â”€â”€ airflow/
â”‚       â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ requirements.txt # Dependencias globales del proyecto
â”œâ”€â”€ mlflow.sql # Script de inicializaciÃ³n de la DB de MLflow
â”œâ”€â”€ docker-compose.yaml # OrquestaciÃ³n de servicios
â””â”€â”€ README.md # DocumentaciÃ³n del proyecto
```

### Comandos Ãºtiles

***Requerimientos***

- *Docker* o *docker desktop* instalados

***Comandos***

- Para correr el proyecto:
  - `cd ./OPERACIONES-APRENDIZAJE-MAQUINA`.
  - `docker compose up`.
  - Opcionalmente `docker compose -f docker-compose.yaml up` para espeficiar el archivo compose.
- Para hacer build luego de actualizar imÃ¡genes y/o `docker-compose.yaml`:
  - `cd ./OPERACIONES-APRENDIZAJE-MAQUINA`.
  - `docker compose build`.
- Para hacer build y ejecutar nuevas imÃ¡genes:
  - `cd ./OPERACIONES-APRENDIZAJE-MAQUINA`.
  - `docker compose up --build`
- Para borrar los containers:
  - `cd ./OPERACIONES-APRENDIZAJE-MAQUINA`.
  - `docker compose down`.
  - Opcionalmente `docker compose down -v` para borrar los ***volÃºmenes*** creados.
- ***RecomendaciÃ³n***
  - Si se realizaron varios cambios en los dockerfiles y al hacer `docker compose up --build` estos no se detectan, eliminar containers, volÃºmenes e imÃ¡genes (fuerza bruta).
  - `docker compose down -v` para eliminar containers y volÃºmenes.
  - En docker desktop, ir a imÃ¡genes y seleccionar aquellas que se desean borrar.
  - Luego, volver a ejecutar `docker compose up`.
  - ***TODO***: buscar como eliminar imÃ¡genes mediante *cli*.
  - ***TODO***: buscar comando para levantar todo nuevamente (rebuild?).
